{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import pickle\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import sklearn\n",
    "import scipy.stats as stats\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './en_us.json' # Game data containing champion, traits, augemnts items \n",
    "with open(file_path, 'r') as json_file:\n",
    "\tdata_dragon = json.load(json_file)\n",
    "data_dragon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.DataFrame(data_dragon['items']) # Make item table\n",
    "\n",
    "game_set = pd.DataFrame(data_dragon['sets']) # filtering only champions and traits: sets8 --> data from season 8\n",
    "\n",
    "season8_trait = pd.DataFrame(pd.DataFrame(data_dragon['sets']).loc['traits', '8']) \n",
    "season8_champ = pd.DataFrame(pd.DataFrame(data_dragon['sets']).loc['champions', '8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dictionary api Name with name that we use in game ex. TFT8_Renekton -> Renekton\n",
    "\n",
    "item_aug_list = {items.loc[i, 'apiName'] : items.loc[i, 'name'] for i in range(items.shape[0])}\n",
    "trait_list = {season8_trait.loc[i, 'apiName'] : season8_trait.loc[i, 'name'] for i in range(season8_trait.shape[0])}\n",
    "champ_list = {season8_champ.loc[i, 'apiName'] : season8_champ.loc[i, 'name'] for i in range(season8_champ.shape[0])}\n",
    "\n",
    "item_aug_list['None'] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = pd.read_csv('match_record_050422023.csv', index_col=[0])\n",
    "game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out previous seson (Only take 8.5 seasonl, not 8)\n",
    "import re\n",
    "pattern = re.compile(r'Version 13\\.6\\.499\\.7758')\n",
    "df = game[game['info.game_version'].str.contains(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only participants info. Check the how table looks like\n",
    "participants = df['info.participants']\n",
    "participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary for further processing unless occurs error\n",
    "participants = participants.str.replace(\"\\'\", \"\\\"\")\n",
    "participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = pd.json_normalize(participants.apply(json.loads))\n",
    "participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make daytime into 0000/00/00 form\n",
    "def add_date(game_summary, game_result,index):\n",
    "    game_id = game_result.iloc[index][\"metadata.match_id\"]\n",
    "    date = str(datetime.fromtimestamp(int(game_result.iloc[index]['info.game_datetime'])/1000)).split(' ')[0]\n",
    "    \n",
    "    game_summary['Game_id'] = game_id\n",
    "    game_summary['Datetime'] = date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_augment(game_summary, pariticpant):\n",
    "\n",
    "    augment = []\n",
    "\n",
    "    for augments in pariticpant['augments']:\n",
    "\n",
    "        augments = augments + ['None']*(3-len(augments)) # If no augment: make in 'None'.\n",
    "        # Make aug dictionary\n",
    "        aug = {\"augment1\":item_aug_list[augments[0]],\"augment2\":item_aug_list[augments[1]],\"augment3\":item_aug_list[augments[2]]}\n",
    "\n",
    "        augment.append(aug)\n",
    "        \n",
    "    augment_df = pd.DataFrame(dict(augment = augment))\n",
    "\n",
    "    game_summary[['augments']] = augment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trait(game_summary, participant):\n",
    "    traits = []\n",
    "\n",
    "    for i in range(participant.shape[0]):\n",
    "\n",
    "        check_trait = participant.loc[i, 'traits']\n",
    "        trait_dict = {}\n",
    "        traits_list = []\n",
    "        num_units_list = []\n",
    "        tier_current_list = []\n",
    "        for j in check_trait:\n",
    "            traits_list.append(trait_list[j['name']]) # Trait as Key\n",
    "            num_units_list.append(j['num_units']) # Number of used units of deck for speciific traits\n",
    "            tier_current_list.append(j['tier_current']) # Acticated corresponding traits \n",
    "        # Make trait dict with  {Trait: {num_units:0, tier:0}}\n",
    "        for i in range(len(traits_list)):\n",
    "            trait_dict[traits_list[i]] = {'num_units': num_units_list[i], 'tier_current': tier_current_list[i]}\n",
    "        traits.append(trait_dict)\n",
    "\n",
    "    game_summary['traits'] = traits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_unit(game_summary, participant):\n",
    "    units = []\n",
    "\n",
    "    for i in range(participant.shape[0]):\n",
    "\n",
    "        check_unit = participant.loc[i, 'units']\n",
    "        unit_dict = {}\n",
    "        units_list = []\n",
    "        unit_tier_list = []\n",
    "        item_name_list = []\n",
    "        for j in check_unit:\n",
    "            units_list.append(champ_list[j['character_id']]) # Used Champions as key\n",
    "            item_name_list.append(j['itemNames']) # Used items of correspsonding champion with list form (can contain multiple items)\n",
    "            unit_tier_list.append(j['tier']) # Tier of corresponding champion\n",
    "        \n",
    "        for i in range(len(units_list)):\n",
    "            unit_dict[units_list[i]] = {'items': item_name_list[i], 'tier_current': unit_tier_list[i]}\n",
    "        units.append(unit_dict)\n",
    "        \n",
    "    game_summary['units'] = units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make first row of participant table\n",
    "participant_s =  json_normalize(participants.iloc[0,:])\n",
    "# Take only necessary info\n",
    "game_summaries = participant_s[['puuid', 'placement', 'time_eliminated', 'last_round', 'total_damage_to_players', 'gold_left']]\n",
    "\n",
    "game_summary = game_summaries\n",
    "\n",
    "add_date(game_summaries,game,0)\n",
    "add_augment(game_summaries, participant_s)\n",
    "add_trait(game_summaries, participant_s)\n",
    "add_unit(game_summaries, participant_s)\n",
    "\n",
    "\n",
    "\n",
    "for num in range(1,participants.shape[0]):\n",
    "    participant =  json_normalize(participants.iloc[num,:])\n",
    "    game_summary = participant[['puuid', 'placement', 'time_eliminated', 'last_round', 'total_damage_to_players', 'gold_left']]\n",
    "\n",
    "    add_date(game_summary,game,num)\n",
    "    add_augment(game_summary, participant)\n",
    "    add_trait(game_summary, participant)\n",
    "    add_unit(game_summary, participant)\n",
    "    game_summaries = pd.concat([game_summaries,game_summary])\n",
    "\n",
    "    \n",
    "# Rearrange columns\n",
    "colname = ['Player_id', 'Placement', 'Time', 'Last_round', 'Damage_player', 'Gold_left', 'Game_id', 'Datetime', 'augments',  'traits', 'units']\n",
    "game_summaries.columns = colname\n",
    "game_summaries = game_summaries[['Datetime', 'Game_id', 'Player_id', 'Placement', 'Time', 'Last_round', 'Damage_player', 'Gold_left', 'augments',  'traits', 'units']]\n",
    "\n",
    "game_summaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save table for further usage\n",
    "game_summaries.to_csv(\"final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get champion infromation from csv (same info table form eu_us.json(data dragon above))\n",
    "champ_list = pd.read_csv('champ.csv') \n",
    "champ_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count champions used in each deck\n",
    "game_champ_list = {i : [0]*game_summaries.shape[0] for i in list(champ_list[\"name\"])}\n",
    "\n",
    "for i in range(len(game_summaries['units'])):\n",
    "    \n",
    "    units = list(game_summaries.iloc[i]['units'].keys())\n",
    "    \n",
    "    for unit in units:\n",
    "        game_champ_list[unit][i] +=1\n",
    "    \n",
    "\n",
    "game_champ_list = pd.DataFrame(game_champ_list)\n",
    "game_champ_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_champ_list.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation between champions with peason correlation -> Find cloely related champions\n",
    "check_cor = game_champ_list.corr(method = 'pearson')\n",
    "\n",
    "check_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_list = {}\n",
    "\n",
    "correlation_dist = []\n",
    "\n",
    "first_champ = []\n",
    "\n",
    "second_champ = []\n",
    "\n",
    "for i in range(check_cor.shape[0]):\n",
    "    for j in range(i, check_cor.shape[0]):\n",
    "        first_champ.append(check_cor.keys()[i])\n",
    "        second_champ.append(check_cor.keys()[j])\n",
    "        correlation_dist.append(check_cor.iloc[i][j])\n",
    "\n",
    "correlation_df = pd.DataFrame(dict(first_champ = first_champ, second_champ = second_champ, cor = correlation_dist))\n",
    "correlation_df = correlation_df[correlation_df.first_champ != correlation_df.second_champ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zac is respawned when trait Riftwalker is activated (Vex, Jhin, Pyke) --> Right correlation\n",
    "correlation_df.sort_values('cor', ascending=False).reset_index(drop=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data_frame = correlation_df, x='cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_contingency_table(dataframe, champion1, champion2):\n",
    "    \n",
    "    result = pd.crosstab(dataframe[champion1], dataframe[champion2])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cramer_v(df, champion1, champion2):\n",
    "    \n",
    "    \n",
    "    dataframe = make_contingency_table(df, champion1, champion2)\n",
    "    \n",
    "    x2 = stats.chi2_contingency(dataframe, correction=False)[0]\n",
    "    N = np.sum(np.sum(dataframe))\n",
    "    minimum_dimension = min(dataframe.shape)-1\n",
    "\n",
    "    return(np.sqrt(x2/N)/minimum_dimension)\n",
    "\n",
    "\n",
    "make_cramer_v(game_champ_list, 'Ashe', 'Renekton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df = correlation_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_cramer_v = []\n",
    "\n",
    "for i in range(correlation_df.shape[0]):\n",
    "    first_champ = correlation_df.first_champ[i]\n",
    "    second_champ = correlation_df.second_champ[i]\n",
    "    \n",
    "    check_cramer_v.append(make_cramer_v(game_champ_list, first_champ, second_champ))\n",
    "\n",
    "correlation_df['cramer_v'] = check_cramer_v\n",
    "\n",
    "correlation_df.sort_values('cramer_v', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kendall(dataframe, champion1, champion2):\n",
    "    \n",
    "    tau, p_value = stats.kendalltau(dataframe[champion1], dataframe[champion2])\n",
    "    \n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_kendall = []\n",
    "\n",
    "for i in range(correlation_df.shape[0]):\n",
    "    first_champ = correlation_df.first_champ[i]\n",
    "    second_champ = correlation_df.second_champ[i]\n",
    "    \n",
    "    check_kendall.append(make_kendall(game_champ_list, first_champ, second_champ))\n",
    "    \n",
    "correlation_df['kendall'] = check_kendall\n",
    "\n",
    "correlation_df.sort_values('kendall', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.sort_values('kendall', key= lambda x : abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_df = pd.DataFrame({i : [0]*len(game_champ_list.columns) for i in game_champ_list.columns})\n",
    "\n",
    "heatmap_df.index = game_champ_list.columns\n",
    "\n",
    "for i in range(heatmap_df.shape[0]):\n",
    "    for j in range(heatmap_df.shape[1]):\n",
    "        first_champ = heatmap_df.index[i]\n",
    "        second_champ = heatmap_df.columns[j]\n",
    "        \n",
    "        kendall = make_kendall(game_champ_list, first_champ, second_champ)\n",
    "        \n",
    "        heatmap_df.iloc[i, j] = kendall\n",
    "\n",
    "px.imshow(heatmap_df, color_continuous_scale = 'RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(heatmap_df, color_continuous_scale = 'RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_cramer_v = []\n",
    "\n",
    "for i in range(correlation_df.shape[0]):\n",
    "    first_champ = correlation_df.first_champ[i]\n",
    "    second_champ = correlation_df.second_champ[i]\n",
    "    \n",
    "    check_cramer_v.append(make_cramer_v(game_champ_list, first_champ, second_champ))\n",
    "\n",
    "correlation_df['cramer_v'] = check_cramer_v\n",
    "\n",
    "correlation_df.sort_values('cramer_v', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data_frame = correlation_df, x='kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.sort_values('cor', ascending=True).reset_index(drop=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.sort_values('cor', ascending=True, key = lambda x : abs(x)).reset_index(drop=True).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_heatmap = px.imshow(check_cor, color_continuous_scale = 'RdBu')\n",
    "\n",
    "cor_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = np.array(game_champ_list).astype(float)\n",
    "\n",
    "check = torch.tensor(check)\n",
    "\n",
    "svd_u, svd_s, svd_v = torch.svd(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_number = svd_s/torch.sum(svd_s)\n",
    "\n",
    "condition_number = condition_number.numpy()\n",
    "\n",
    "condition_number_ex = []\n",
    "\n",
    "for i in range(len(condition_number)):\n",
    "    condition_number_ex.append(sum(condition_number[:i+1]))\n",
    "    \n",
    "scree_ploting=pd.DataFrame(dict(number = range(1, len(condition_number)+1),  condition_number = condition_number_ex))\n",
    "\n",
    "scree_plot = px.line(data_frame = scree_ploting, x='number', y='condition_number', markers=True)\n",
    "\n",
    "scree_plot.update_layout(title = 'Scree plot')\n",
    "\n",
    "# cummulative sum이 0.8을 넘는 지점인 36을 기준으로 선택, 차원을 축소시켰다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_value = pd.DataFrame(svd_u.numpy()).iloc[:, :36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환된 새로운 값을 이용하여 KMeans를 적용했다. best cluster 수를 찾기 위해 2부터 20까지 within sum of square을 비교했다.\n",
    "\n",
    "check = []\n",
    "\n",
    "for i in range(2, 30):\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=i, random_state=15).fit(changed_value.iloc[:, 0:36])\n",
    "    \n",
    "    check.append(kmeans.inertia_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_k = px.line(x= range(2, 30), y=check, markers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_k\n",
    "\n",
    "# 비교 결과 cluster 수가 14 이후 감소율이 작아진다. 따라서 K=14일 때의 결과를 확인했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=8).fit(changed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "kmeans = KMeans(n_clusters=8).fit(changed_value)\n",
    "\n",
    "cluster_check = {'cluster' + str(i+1) : game_champ_list[kmeans.labels_==i] for i in range(8)}\n",
    "\n",
    "cluster_count = {'cluster' + str(i+1) : pd.DataFrame(cluster_check['cluster'+str(i+1)].apply(sum, 0)) for i in range(8)}\n",
    "\n",
    "for i in cluster_count.keys():\n",
    "    cluster_count[i]['champ'] = cluster_count[i].index\n",
    "    cluster_count[i] = cluster_count[i].reset_index(drop=True)\n",
    "    cluster_count[i].columns = [i, 'champ']\n",
    "\n",
    "\n",
    "cluster_result = [cluster_count[i] for i in cluster_count.keys()]\n",
    "\n",
    "result = reduce(lambda x, y : pd.merge(x, y, on='champ'), cluster_result)\n",
    "\n",
    "result = result[['champ']+ [f'cluster{i+1}' for i in range(8)]]\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values('cluster8', ascending=False).reset_index(drop=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trait = pd.read_csv('trait.csv')    \n",
    "trait_list = list(trait[\"name\"])\n",
    "trait_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_all_list = {i : [0]*game_summaries.shape[0] for i in list(champ_list[\"name\"])}\n",
    "\n",
    "for i in trait_list:\n",
    "    game_all_list[i] = [0]*game_summaries.shape[0]\n",
    "\n",
    "\n",
    "for i in range(len(game_summaries['units'])):\n",
    "\n",
    "    units = list(game_summaries.iloc[i]['units'].keys())\n",
    "    \n",
    "    for unit in units:\n",
    "        game_all_list[unit][i] +=1\n",
    "\n",
    "    traits = list(game_summaries.iloc[i]['traits'].keys())\n",
    "    num_tier = list(game_summaries.iloc[i]['traits'].values())\n",
    "    tier = []\n",
    "    for j in num_tier:\n",
    "        tier.append(list(j.values())[1])\n",
    "    \n",
    "    if len(traits)==0:\n",
    "        pass\n",
    "    else:\n",
    "        for k in range(len(traits)):\n",
    "            game_all_list[traits[k]][i] += tier[k]\n",
    "    \n",
    "\n",
    "game_all_list = pd.DataFrame(game_all_list)\n",
    "game_all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_all = np.array(game_all_list).astype(float)\n",
    "\n",
    "check_all = torch.tensor(check_all)\n",
    "\n",
    "svd_u_all, svd_s_all, svd_v_all = torch.svd(check_all)\n",
    "\n",
    "condition_number_all = svd_s_all/torch.sum(svd_s_all)\n",
    "\n",
    "condition_number_all = condition_number_all.numpy()\n",
    "\n",
    "condition_number_all_ex = []\n",
    "\n",
    "for i in range(len(condition_number_all)):\n",
    "    condition_number_all_ex.append(sum(condition_number_all[:i+1]))\n",
    "    \n",
    "\n",
    "scree_plot_all = px.line(x=range(1, 98), y=condition_number_all_ex, markers=True)\n",
    "\n",
    "scree_plot_all.update_xaxes(title = 'singular value number')\n",
    "scree_plot_all.update_yaxes(title = 'condition number')\n",
    "scree_plot_all.update_layout(title = 'Scree plot')\n",
    "\n",
    "scree_plot_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_value_all = pd.DataFrame(svd_u_all.numpy()).iloc[:, :22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_value_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_all = []\n",
    "\n",
    "for i in range(1, 30):\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=i).fit(changed_value_all)\n",
    "    \n",
    "    check_all.append(kmeans.inertia_)\n",
    "    \n",
    "find_k_all = px.line(x= range(1, 30), y=check_all, markers=True)\n",
    "\n",
    "find_k_all.update_layout(title = 'Within Sum of Square')\n",
    "\n",
    "find_k_all.update_xaxes(title = 'number of clusters')\n",
    "\n",
    "find_k_all.update_yaxes(title = 'Within Sum of Square')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_all = KMeans(n_clusters=17).fit(changed_value_all)\n",
    "\n",
    "cluster_check_all = {'cluster' + str(i+1) : game_all_list[kmeans_all.labels_==i] for i in range(17)}\n",
    "\n",
    "cluster_count_all = {'cluster' + str(i+1) : pd.DataFrame(cluster_check_all['cluster'+str(i+1)].apply(sum, 0)) for i in range(17)}\n",
    "\n",
    "for i in cluster_count_all.keys():\n",
    "    cluster_count_all[i]['champ'] = cluster_count_all[i].index\n",
    "    cluster_count_all[i] = cluster_count_all[i].reset_index(drop=True)\n",
    "    cluster_count_all[i].columns = [i, 'champ']\n",
    "\n",
    "\n",
    "cluster_result_all = [cluster_count_all[i] for i in cluster_count_all.keys()]\n",
    "\n",
    "result_all = reduce(lambda x, y : pd.merge(x, y, on='champ'), cluster_result_all)\n",
    "\n",
    "result_all = result_all[['champ']+ [f'cluster{i+1}' for i in range(17)]]\n",
    "\n",
    "result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_champ = result_all.iloc[:68, :]\n",
    "check_trait = result_all.iloc[68:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_cluster = check_champ.sort_values('cluster17', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trait_cluster = check_trait.sort_values('cluster17', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_cluster.to_csv(\"champ_cluster.csv\",index=False)\n",
    "trait_cluster.to_csv(\"trait_cluster.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck_list= ['Star Guardian Neeko', 'Hacker Draven', 'Quickdraw Lucian', 'Supers Heart', 'RiftWalker Mascot', 'Aegis Threat', 'Hacker Warwick', 'Brawler Warwick', 'Anima Squad', 'Renegade Jhin', 'Ox Force Twisted Fate', 'Supers Underground', 'Duelist', 'LaserCorps Warwick', 'Gadgeteen Gnar', 'Mecha:PRIME Samira', 'InfiniTeam']\n",
    "deck_result = [deck_list[kmeans_all.labels_[i]] for i in range(len(kmeans_all.labels_))]\n",
    "\n",
    "game_summaries['Deck'] = deck_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_summaries.to_csv(\"final_cluster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_cluster\",\"wb\") as f:\n",
    "    pickle.dump(game_summaries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_list = pd.read_csv('champ.csv') \n",
    "index = list(champ_list[\"name\"])\n",
    "\n",
    "item_set = []\n",
    "\n",
    "for i in range(len(game_summaries['units'])):\n",
    "\n",
    "    itemtier = list(game_summaries.iloc[i]['units'].values())\n",
    "    for j in range(len(itemtier)):\n",
    "        itemonly = list(itemtier[j].values())[0]\n",
    "        if len(itemonly) != 0:\n",
    "            for k in itemonly:\n",
    "                item_set.append(k)\n",
    "\n",
    "check_item_usage = {i : [0] for i in set(item_set)}\n",
    "item_usage = pd.DataFrame(check_item_usage, index=index)\n",
    "item_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_set = []\n",
    "\n",
    "for i in range(len(game_summaries['augments'])):\n",
    "\n",
    "    augments = list(game_summaries.iloc[i]['augments'].values())\n",
    "    for j in augments:\n",
    "        augment_set.append(j)\n",
    "    \n",
    "check_augment_usage = {i : [0] for i in set(augment_set)}\n",
    "augment_usage = pd.DataFrame(check_augment_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deck_select(cluster_name):\n",
    "    # Make champ item talbe with 0 values\n",
    "    champ_list = pd.read_csv('champ.csv') \n",
    "    index = list(champ_list[\"name\"])\n",
    "\n",
    "    item_set = []\n",
    "\n",
    "    for i in range(len(game_summaries['units'])):\n",
    "\n",
    "        itemtier = list(game_summaries.iloc[i]['units'].values())\n",
    "        for j in range(len(itemtier)):\n",
    "            itemonly = list(itemtier[j].values())[0]\n",
    "            if len(itemonly) != 0:\n",
    "                for k in itemonly:\n",
    "                    item_set.append(k)\n",
    "\n",
    "    check_item_usage = {i : [0] for i in set(item_set)}\n",
    "    item_usage = pd.DataFrame(check_item_usage, index=index)\n",
    "   \n",
    "    #Make augment table with 0 values\n",
    "    augment_set = []\n",
    "\n",
    "    for i in range(len(game_summaries['augments'])):\n",
    "\n",
    "        augments = list(game_summaries.iloc[i]['augments'].values())\n",
    "        for j in augments:\n",
    "            augment_set.append(j)\n",
    "    index_aug = list(set(augment_set))\n",
    "    check_augment_usage = {\"Augment\" : [0]}\n",
    "    #check_augment_usage = {i : [0] for i in set(augment_set)}\n",
    "    augment_usage = pd.DataFrame(check_augment_usage, index=index_aug)\n",
    "\n",
    "    df = game_summaries[game_summaries['Deck'] == cluster_name]\n",
    "\n",
    "    for i in range(len(df['units'])):\n",
    "\n",
    "        itemtier = list(df.iloc[i]['units'].values())\n",
    "        champ = list(df.iloc[i]['units'].keys())\n",
    "        for j in range(len(itemtier)):\n",
    "            itemonly = list(itemtier[j].values())[0]\n",
    "            if len(itemonly) != 0:\n",
    "                for k in itemonly:\n",
    "                    item_usage.loc[champ[j],k] += 1\n",
    "\n",
    "    item_usage[\"Total\"] = item_usage.sum(axis=1)\n",
    "    item_usage_fin = item_usage.sort_values(\"Total\", ascending=False)\n",
    "\n",
    "    for i in range(len(df['augments'])):\n",
    "\n",
    "        augments = list(df.iloc[i]['augments'].values())\n",
    "        for j in augments:\n",
    "            augment_usage.loc[j,\"Augment\"] += 1\n",
    "    \n",
    "    augment_fin = augment_usage.sort_values(\"Augment\", ascending=False)\n",
    "\n",
    "    Game_num = len(df[\"Placement\"])\n",
    "\n",
    "    Total_Placement = 0\n",
    "    for i in df[\"Placement\"]:\n",
    "        Total_Placement += i\n",
    "    Avg_rank = Total_Placement/Game_num #평균 등수\n",
    "\n",
    "    rank1 = 0\n",
    "    for i in df[\"Placement\"]:\n",
    "        if i == 1:\n",
    "            rank1 += i\n",
    "    Win_Rate = rank1/Game_num*100 #승률! 1등한거\n",
    "\n",
    "    rank4 = 0\n",
    "    for i in df[\"Placement\"]:\n",
    "        if i <= 4:\n",
    "            rank4 += 1\n",
    "    U_rank4 = rank4/Game_num*100 #순방률\n",
    "    \n",
    "    return item_usage_fin, augment_fin, Avg_rank, Win_Rate, U_rank4, Game_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemClus1, AugClus1, Avgrank1, Win1, Urank1, Gamenum1 =deck_select(\"Star Guardian Neeko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemClus1.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugClus1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemClus2, AugClus2, Avgrank2, Win2, Urank2, Gamenum2 =deck_select(\"Hacker Draven\")\n",
    "ItemClus3, AugClus3, Avgrank3, Win3, Urank3, Gamenum3 =deck_select(\"Quickdraw Lucian\")\n",
    "ItemClus4, AugClus4, Avgrank4, Win4, Urank4, Gamenum4 =deck_select(\"Supers Heart\")\n",
    "ItemClus5, AugClus5, Avgrank5, Win5, Urank5, Gamenum5 =deck_select(\"RiftWalker Mascot\")\n",
    "ItemClus6, AugClus6, Avgrank6, Win6, Urank6, Gamenum6 =deck_select(\"Aegis Threat\")\n",
    "ItemClus7, AugClus7, Avgrank7, Win7, Urank7, Gamenum7 =deck_select(\"Hacker Warwick\")\n",
    "ItemClus8, AugClus8, Avgrank8, Win8, Urank8, Gamenum8 =deck_select(\"Brawler Warwick\")\n",
    "ItemClus9, AugClus9, Avgrank9, Win9, Urank9, Gamenum9 =deck_select(\"Anima Squad\")\n",
    "ItemClus10, AugClus10, Avgrank10, Win10, Urank10, Gamenum10 =deck_select(\"Renegade Jhin\")\n",
    "ItemClus11, AugClus11, Avgrank11, Win11, Urank11, Gamenum11 =deck_select(\"Ox Force Twisted Fate\")\n",
    "ItemClus12, AugClus12, Avgrank12, Win12, Urank12, Gamenum12 =deck_select(\"Supers Underground\")\n",
    "ItemClus13, AugClus13, Avgrank13, Win13, Urank13, Gamenum13 =deck_select(\"Duelist\")\n",
    "ItemClus14, AugClus14, Avgrank14, Win14, Urank14, Gamenum14 =deck_select(\"LaserCorps Warwick\")\n",
    "ItemClus15, AugClus15, Avgrank15, Win15, Urank15, Gamenum15 =deck_select(\"Gadgeteen Gnar\")\n",
    "ItemClus16, AugClus16, Avgrank16, Win16, Urank16, Gamenum16 =deck_select(\"Mecha:PRIME Samira\")\n",
    "ItemClus17, AugClus17, Avgrank17, Win17, Urank17, Gamenum17 =deck_select(\"InfiniTeam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_item(ItemClustable,itemlist):\n",
    "    table = ItemClustable\n",
    "    table_largest = table.apply(lambda x: x.nlargest(6), axis=1)\n",
    "    table_largest = table_largest.T\n",
    "    table_sorted = table_largest.apply(lambda x: x.sort_values().index.tolist())\n",
    "\n",
    "    Main_champ = list(table_sorted.columns)[:3]\n",
    "    Main_dict = {}\n",
    "    main1 = []\n",
    "    main2 = []\n",
    "    main3 = []\n",
    "    for i in range(5):\n",
    "        main1.append(itemlist[table_sorted.iloc[i][0]])\n",
    "        main2.append(itemlist[table_sorted.iloc[i][1]])\n",
    "        main3.append(itemlist[table_sorted.iloc[i][2]])\n",
    "    Main_dict[Main_champ[0]] = main1[::-1]\n",
    "    Main_dict[Main_champ[1]] = main2[::-1]\n",
    "    Main_dict[Main_champ[2]] = main3[::-1]\n",
    "\n",
    "    return Main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Meta_deck_dict = {\"Deck_Name\":[], \"MainChamp_and_Item\":[], \"Main_Augment\":[], \"Average_Rank\":[], \"Win_Rate\":[], \"Under_Rank4\":[], \"Used_num\":[] }\n",
    "for i in range(1,18):\n",
    "    item_num = eval(\"ItemClus\" + str(i))\n",
    "    aug_num = eval(\"AugClus\" + str(i))\n",
    "    avg_num = eval(\"Avgrank\" + str(i))\n",
    "    wr_num = eval(\"Win\" + str(i))\n",
    "    ur_num = eval(\"Urank\" + str(i))\n",
    "    un_num = eval(\"Gamenum\" + str(i))\n",
    "\n",
    "    Meta_deck_dict['Deck_Name'].append(deck_list[i-1])\n",
    "    Meta_deck_dict['MainChamp_and_Item'].append(main_item(item_num,item_aug_list))\n",
    "    Meta_deck_dict['Main_Augment'].append(list(aug_num.head(10).index))\n",
    "    Meta_deck_dict['Average_Rank'].append(avg_num)\n",
    "    Meta_deck_dict['Win_Rate'].append(wr_num)\n",
    "    Meta_deck_dict['Under_Rank4'].append(ur_num)\n",
    "    Meta_deck_dict['Used_num'].append(un_num)\n",
    "\n",
    "Meta_summary = pd.DataFrame.from_dict(Meta_deck_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Meta_summary = Meta_summary.sort_values(\"Average_Rank\", ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Meta_summary.to_csv(\"Meta_deck.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
